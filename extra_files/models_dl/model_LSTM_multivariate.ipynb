{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3789dbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9a06873eff86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#import numpy as np \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc742a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters \n",
    "n_steps = 5\n",
    "units = 20 \n",
    "layers = 4\n",
    "drop = 0.2\n",
    "epochs = 1\n",
    "batch_size = 10\n",
    "optimizer = 'adam'\n",
    "second_variable = 'residential_percent_change_from_baseline'\n",
    "second_varible_metric = 'mean'\n",
    "dim_test = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08707e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PART1 - DATA PROCESSING\"\"\"\n",
    "\n",
    "#import dataset\n",
    "\n",
    "df = pd.read_csv('/home/luis/workspace/covid_visualization/dataset.csv')\n",
    "print(df)\n",
    "X = df  #Guarda a partir da coluna 3 (4) atÃ© a penultima\n",
    "X_1 = X.groupby(['week_predicton'])['last_week_cases'].agg('sum')\n",
    "X_1 = pd.DataFrame(X_1)\n",
    "sc_1 = MinMaxScaler(feature_range = (0,1)) \n",
    "X_1 = sc_1.fit_transform(X_1)\n",
    "\n",
    "X_2 = X.groupby(['week_predicton'])[second_variable].agg(second_varible_metric)\n",
    "X_2 = pd.DataFrame(X_2)\n",
    "sc_2 = MinMaxScaler(feature_range = (0,1)) \n",
    "X_2 = sc_2.fit_transform(X_2)\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "\n",
    "# define input sequence\n",
    "in_seq1 = X_1\n",
    "in_seq2 = X_2\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# choose a number of time steps\n",
    "n_steps = n_steps\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps = n_steps\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "X_test = X[-dim_test:]\n",
    "y_test = y[-dim_test:]\n",
    "X = X[:-dim_test]\n",
    "y = y[:-dim_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318dfddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"PART2 - BUILDING THE LSTM\"\"\"\n",
    "\n",
    "# Adding the first LSTM layer and some dropout regularization\n",
    "model = Sequential()\n",
    "model.add(LSTM(units = units, return_sequences = True, input_shape=(n_steps, n_features)))\n",
    "model.add(Dropout(drop))\n",
    "\n",
    "# Adding the second LSTM layer and some dropout regularization\n",
    "i = 0\n",
    "while i < layers:\n",
    "    model.add(LSTM(units = units, return_sequences = True))\n",
    "    model.add(Dropout(drop))\n",
    "    i += 1\n",
    "\n",
    "model.add(LSTM(units = units, return_sequences = False))\n",
    "model.add(Dropout(drop))\n",
    "\n",
    "#Adding the output layer \n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbe06fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Part3 - Training The LSTM \"\"\"\n",
    "\n",
    "# Compiling the RNN \n",
    "model.compile(optimizer = optimizer, loss = 'mean_squared_error')\n",
    "\n",
    "#Fitting the RNN to Training set\n",
    "\n",
    "history = model.fit(X, y, epochs = epochs, batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33bafee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(history.history['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cafca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = model.predict(X_test)\n",
    "predicted_stock_price = sc_1.inverse_transform(predicted_stock_price)\n",
    "y_test = sc_1.inverse_transform(array(y_test.reshape(1, -1)))\n",
    "y_test = y_test[0]\n",
    "# Vizualizing the Results\n",
    "plt.plot(y_test, color = 'red', label = 'Real')\n",
    "plt.plot(predicted_stock_price, color = 'green', label = 'Predicted')\n",
    "plt.title('Covid Predicton')\n",
    "plt.xlabel('week')\n",
    "plt.ylabel('cases')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(abs(sum((predicted_stock_price-y_test)**2)/dim_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e137e1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
